\documentclass[12pt]{article}
%% ODER: format ==         = "\mathrel{==}"
%% ODER: format /=         = "\neq "
%
%
\makeatletter
\@ifundefined{lhs2tex.lhs2tex.sty.read}%
  {\@namedef{lhs2tex.lhs2tex.sty.read}{}%
   \newcommand\SkipToFmtEnd{}%
   \newcommand\EndFmtInput{}%
   \long\def\SkipToFmtEnd#1\EndFmtInput{}%
  }\SkipToFmtEnd

\newcommand\ReadOnlyOnce[1]{\@ifundefined{#1}{\@namedef{#1}{}}\SkipToFmtEnd}
\usepackage{amstext}
\usepackage{amssymb}
\usepackage{stmaryrd}
\DeclareFontFamily{OT1}{cmtex}{}
\DeclareFontShape{OT1}{cmtex}{m}{n}
  {<5><6><7><8>cmtex8
   <9>cmtex9
   <10><10.95><12><14.4><17.28><20.74><24.88>cmtex10}{}
\DeclareFontShape{OT1}{cmtex}{m}{it}
  {<-> ssub * cmtt/m/it}{}
\newcommand{\texfamily}{\fontfamily{cmtex}\selectfont}
\DeclareFontShape{OT1}{cmtt}{bx}{n}
  {<5><6><7><8>cmtt8
   <9>cmbtt9
   <10><10.95><12><14.4><17.28><20.74><24.88>cmbtt10}{}
\DeclareFontShape{OT1}{cmtex}{bx}{n}
  {<-> ssub * cmtt/bx/n}{}
\newcommand{\tex}[1]{\text{\texfamily#1}}	% NEU

\newcommand{\Sp}{\hskip.33334em\relax}


\newcommand{\Conid}[1]{\mathit{#1}}
\newcommand{\Varid}[1]{\mathit{#1}}
\newcommand{\anonymous}{\kern0.06em \vbox{\hrule\@width.5em}}
\newcommand{\plus}{\mathbin{+\!\!\!+}}
\newcommand{\bind}{\mathbin{>\!\!\!>\mkern-6.7mu=}}
\newcommand{\rbind}{\mathbin{=\mkern-6.7mu<\!\!\!<}}% suggested by Neil Mitchell
\newcommand{\sequ}{\mathbin{>\!\!\!>}}
\renewcommand{\leq}{\leqslant}
\renewcommand{\geq}{\geqslant}
\usepackage{polytable}

%mathindent has to be defined
\@ifundefined{mathindent}%
  {\newdimen\mathindent\mathindent\leftmargini}%
  {}%

\def\resethooks{%
  \global\let\SaveRestoreHook\empty
  \global\let\ColumnHook\empty}
\newcommand*{\savecolumns}[1][default]%
  {\g@addto@macro\SaveRestoreHook{\savecolumns[#1]}}
\newcommand*{\restorecolumns}[1][default]%
  {\g@addto@macro\SaveRestoreHook{\restorecolumns[#1]}}
\newcommand*{\aligncolumn}[2]%
  {\g@addto@macro\ColumnHook{\column{#1}{#2}}}

\resethooks

\newcommand{\onelinecommentchars}{\quad-{}- }
\newcommand{\commentbeginchars}{\enskip\{-}
\newcommand{\commentendchars}{-\}\enskip}

\newcommand{\visiblecomments}{%
  \let\onelinecomment=\onelinecommentchars
  \let\commentbegin=\commentbeginchars
  \let\commentend=\commentendchars}

\newcommand{\invisiblecomments}{%
  \let\onelinecomment=\empty
  \let\commentbegin=\empty
  \let\commentend=\empty}

\visiblecomments

\newlength{\blanklineskip}
\setlength{\blanklineskip}{0.66084ex}

\newcommand{\hsindent}[1]{\quad}% default is fixed indentation
\let\hspre\empty
\let\hspost\empty
\newcommand{\NB}{\textbf{NB}}
\newcommand{\Todo}[1]{$\langle$\textbf{To do:}~#1$\rangle$}

\EndFmtInput
\makeatother
%
%
%
%
%
%
% This package provides two environments suitable to take the place
% of hscode, called "plainhscode" and "arrayhscode". 
%
% The plain environment surrounds each code block by vertical space,
% and it uses \abovedisplayskip and \belowdisplayskip to get spacing
% similar to formulas. Note that if these dimensions are changed,
% the spacing around displayed math formulas changes as well.
% All code is indented using \leftskip.
%
% Changed 19.08.2004 to reflect changes in colorcode. Should work with
% CodeGroup.sty.
%
\ReadOnlyOnce{polycode.fmt}%
\makeatletter

\newcommand{\hsnewpar}[1]%
  {{\parskip=0pt\parindent=0pt\par\vskip #1\noindent}}

% can be used, for instance, to redefine the code size, by setting the
% command to \small or something alike
\newcommand{\hscodestyle}{}

% The command \sethscode can be used to switch the code formatting
% behaviour by mapping the hscode environment in the subst directive
% to a new LaTeX environment.

\newcommand{\sethscode}[1]%
  {\expandafter\let\expandafter\hscode\csname #1\endcsname
   \expandafter\let\expandafter\endhscode\csname end#1\endcsname}

% "compatibility" mode restores the non-polycode.fmt layout.

\newenvironment{compathscode}%
  {\par\noindent
   \advance\leftskip\mathindent
   \hscodestyle
   \let\\=\@normalcr
   \let\hspre\(\let\hspost\)%
   \pboxed}%
  {\endpboxed\)%
   \par\noindent
   \ignorespacesafterend}

\newcommand{\compaths}{\sethscode{compathscode}}

% "plain" mode is the proposed default.
% It should now work with \centering.
% This required some changes. The old version
% is still available for reference as oldplainhscode.

\newenvironment{plainhscode}%
  {\hsnewpar\abovedisplayskip
   \advance\leftskip\mathindent
   \hscodestyle
   \let\hspre\(\let\hspost\)%
   \pboxed}%
  {\endpboxed%
   \hsnewpar\belowdisplayskip
   \ignorespacesafterend}

\newenvironment{oldplainhscode}%
  {\hsnewpar\abovedisplayskip
   \advance\leftskip\mathindent
   \hscodestyle
   \let\\=\@normalcr
   \(\pboxed}%
  {\endpboxed\)%
   \hsnewpar\belowdisplayskip
   \ignorespacesafterend}

% Here, we make plainhscode the default environment.

\newcommand{\plainhs}{\sethscode{plainhscode}}
\newcommand{\oldplainhs}{\sethscode{oldplainhscode}}
\plainhs

% The arrayhscode is like plain, but makes use of polytable's
% parray environment which disallows page breaks in code blocks.

\newenvironment{arrayhscode}%
  {\hsnewpar\abovedisplayskip
   \advance\leftskip\mathindent
   \hscodestyle
   \let\\=\@normalcr
   \(\parray}%
  {\endparray\)%
   \hsnewpar\belowdisplayskip
   \ignorespacesafterend}

\newcommand{\arrayhs}{\sethscode{arrayhscode}}

% The mathhscode environment also makes use of polytable's parray 
% environment. It is supposed to be used only inside math mode 
% (I used it to typeset the type rules in my thesis).

\newenvironment{mathhscode}%
  {\parray}{\endparray}

\newcommand{\mathhs}{\sethscode{mathhscode}}

% texths is similar to mathhs, but works in text mode.

\newenvironment{texthscode}%
  {\(\parray}{\endparray\)}

\newcommand{\texths}{\sethscode{texthscode}}

% The framed environment places code in a framed box.

\def\codeframewidth{\arrayrulewidth}
\RequirePackage{calc}

\newenvironment{framedhscode}%
  {\parskip=\abovedisplayskip\par\noindent
   \hscodestyle
   \arrayrulewidth=\codeframewidth
   \tabular{@{}|p{\linewidth-2\arraycolsep-2\arrayrulewidth-2pt}|@{}}%
   \hline\framedhslinecorrect\\{-1.5ex}%
   \let\endoflinesave=\\
   \let\\=\@normalcr
   \(\pboxed}%
  {\endpboxed\)%
   \framedhslinecorrect\endoflinesave{.5ex}\hline
   \endtabular
   \parskip=\belowdisplayskip\par\noindent
   \ignorespacesafterend}

\newcommand{\framedhslinecorrect}[2]%
  {#1[#2]}

\newcommand{\framedhs}{\sethscode{framedhscode}}

% The inlinehscode environment is an experimental environment
% that can be used to typeset displayed code inline.

\newenvironment{inlinehscode}%
  {\(\def\column##1##2{}%
   \let\>\undefined\let\<\undefined\let\\\undefined
   \newcommand\>[1][]{}\newcommand\<[1][]{}\newcommand\\[1][]{}%
   \def\fromto##1##2##3{##3}%
   \def\nextline{}}{\) }%

\newcommand{\inlinehs}{\sethscode{inlinehscode}}

% The joincode environment is a separate environment that
% can be used to surround and thereby connect multiple code
% blocks.

\newenvironment{joincode}%
  {\let\orighscode=\hscode
   \let\origendhscode=\endhscode
   \def\endhscode{\def\hscode{\endgroup\def\@currenvir{hscode}\\}\begingroup}
   %\let\SaveRestoreHook=\empty
   %\let\ColumnHook=\empty
   %\let\resethooks=\empty
   \orighscode\def\hscode{\endgroup\def\@currenvir{hscode}}}%
  {\origendhscode
   \global\let\hscode=\orighscode
   \global\let\endhscode=\origendhscode}%

\makeatother
\EndFmtInput
%
\newcommand{\proves}{\vdash}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem*{remark}{Remark}

\title{The Curry-Howard correspondence for Propositional Logic}
\date{2022 February 28}
\author{Edgar Lin}
\begin{document}
\maketitle
\section{Introduction}
Intuitionistic logic attempts to formalize the the \textit{BHK-interpretation} (named for Brouwer, Heyting, and Kolmogorov) of logical connectives. 
In particular, the BHK-interpretation of the logical connective $\to$ holds that a proof of $\varphi_1\to\varphi_2$ is a program transforming any demonstration of $\varphi_1$ into one of $\varphi_2$. 
In order to demonstrate that a proof-system in intuitionistic logic properly formalizes the BHK-interpretation, then, we would like to show that any proof of $\varphi_1\to\varphi_2$ does in fact correspond to a program in some formalism of computation that takes some representation of a proof of $\varphi_1$ to a proof of $\varphi_2$.  

This correspondence is called the Curry-Howard correspondence. Here, we will explicate the Curry-Howard correspondence between the natural deduction proof-system for the implicational fragment of intuitionistic propositional logic, that is, the subset of intuitionistic propositional logic that only uses the logical connectives $\to$ and $\bot$, and the simply-typed lambda calculus, a formalism for representing computable functions. 

The Curry-Howard isomorphism goes as follows: first, we interpret sentences in propositional logic as types of expressions in the simply-typed lambda calculus, in particular, we interpret sentences of the form $\varphi\to\psi$ as types of functions from expressions of the type corresponding to $\varphi$ to expressions of the type corresponding to $\psi$. 
Then, a proof of a sentence is simply an expression in the simply-typed lambda calculus whose type is that sentence. 
The Curry-Howard correspondence, then, states 
that provability in intuitionistic propositional logic is equivalent to type-inhabitation in the simply typed lambda-calculus 
by providing a correspondence between every natural deduction proof of a sentence in intuitionistic propositional logic and 
every term in the simply-typed lambda calculus such that the type of the lambda-term is the sentence to be proved. 
Further, this correspondence is computable by a structure-preserving transformation between the abstract syntax-trees of the proof and the program.  

In the following sections, we will outline the implicational fragment of intuitionistic propositional logic (IPC($\to$)) along with the natural deduction proof system, before demonstrating the Curry-Howard isomorphism between the two systems and some of its uses and abuses. When it comes to demonstrating the computational properties of the correspondence, we will write our computations as Haskell programs instead of using formal systems of defining computations for the sake of readability. 
 
\section{The Natural Deduction Proof System for the IPC($\to$)}
The syntactic rules for the implicational fragment of intuitionistic propositional formulae are much the same as that for classical logic. 
We start with a countably infinite set of propositional variables/atomic propositions $PV$. In the implicational fragment we only have one logical connective, $\to$, signifying implication. Then, our set of formulae/sentences $\Phi$ is 
the smallest set of finite strings of characters in containing all of the below: 
\begin{itemize}
\item Every $A\in PV$, 
\item $(A\to B)$ for every $A,B\in \Phi$. 
\end{itemize} 

We note that in particular that we can't explicitly express $\bot$ in the implicational fragment. Thus, the implicational fragment is called a \textit{positive} subset of the full intuitionistic logic. We will later show that this omission doesn't affect the set of (implicational) sentences we can prove. 

We will assume the unique reading lemma. Then, we can equivalently define logical formulae as strings corresponding to the following abstract syntax tree (in Haskell):  
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{16}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\mathbf{module}\;\Conid{CurryHoward}\;\mathbf{where}{}\<[E]%
\\
\>[B]{}\mathbf{import}\;\Varid{qualified}\;\Conid{\Conid{Data}.Set}\;\Varid{as}\;\Conid{Set}{}\<[E]%
\\
\>[B]{}\mathbf{import}\;\Varid{qualified}\;\Conid{\Conid{Data}.Map}\;\Varid{as}\;\Conid{Map}{}\<[E]%
\\
\>[B]{}\mathbf{import}\;\Varid{qualified}\;\Conid{\Conid{Data}.List}\;\Varid{as}\;\Conid{List}{}\<[E]%
\\[\blanklineskip]%
\>[B]{}\mathbf{type}\;\Conid{PV}\mathrel{=}\Conid{String}{}\<[E]%
\\
\>[B]{}\mathbf{data}\;\Conid{Formula}\mathrel{=}\Conid{Atomic}\;\Conid{PV}{}\<[E]%
\\
\>[B]{}\hsindent{16}{}\<[16]%
\>[16]{}\mid \Conid{Implies}\;\Conid{Formula}\;\Conid{Formula}{}\<[E]%
\\
\>[B]{}\hsindent{16}{}\<[16]%
\>[16]{}\mathbf{deriving}\;(\Conid{Show},\Conid{Eq},\Conid{Ord}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks

The conversion back to strings goes as follows:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Varid{formula}\mathbin{::}\Conid{Formula}\to \Conid{String}{}\<[E]%
\\
\>[B]{}\Varid{formula}\;(\Conid{Atomic}\;\Varid{v})\mathrel{=}\Varid{v}{}\<[E]%
\\
\>[B]{}\Varid{formula}\;(\Conid{Implies}\;\Varid{p}\;\Varid{q})\mathrel{=}\text{\ttfamily \char34 (\char34}\plus \Varid{formula}\;\Varid{p}\plus \text{\ttfamily \char34 \char92 \char92 to~\char34}\plus \Varid{formula}\;\Varid{q}\plus \text{\ttfamily \char34 )\char34}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks

A \textit{theory} is a subset $\Gamma\subset\Phi$. We call a finite theory $\Gamma$ a \textit{context}. 
For a formula $\varphi$ we wrote $\Gamma,\phi$ for $\Gamma\cup\{\varphi\}$. 
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\mathbf{type}\;\Conid{Theory}\mathrel{=}\Conid{\Conid{Set}.Set}\;\Conid{Formula}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
For a context $\Gamma$ and a formula $\varphi$ we write $\Gamma\vdash\varphi$ to denote the fact that $\Gamma$ proves $\varphi$.  
We call any $\varphi$ such that $\vdash\varphi$ a theorem of IPC($\to$). 
A proof of $\Gamma\vdash\varphi$ is a (finite) tree whose nodes are labeled with context-formula pairs, which we will denote $\Delta\vdash\psi$, and that obey the following rules:
\begin{itemize}
\item The root node is labeled by $\Gamma\vdash\varphi$, that is, the conclusion of the proof.  
\item The leaf nodes are labeled $\Delta,\psi\vdash\psi$. These correspond to using an axiom in a proof. 
\item Non-leaf nodes have one or more children. The labels of parent nodes are inferred from those of their children by one of the following rules: 
\begin{itemize}
\item Introduction of $\to$ ($\to$ I): From $\Delta,\psi\vdash \pi$, infer $\Delta\vdash\psi\to\pi$.    
\item Elimination of $\to$ ($\to$ E): From $\Delta\vdash \psi\to\pi$ and $\Delta\vdash \psi$, infer $\Delta\vdash \pi$. 
\end{itemize}
\end{itemize}
We can write a natural deduction tree and proof-checking rules in Haskell as follows:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{14}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\mathbf{data}\;\Conid{Proof}\mathrel{=}\Conid{Axiom}\;(\Conid{Theory},\Conid{Formula}){}\<[E]%
\\
\>[B]{}\hsindent{14}{}\<[14]%
\>[14]{}\mid \Conid{Introduction}\;(\Conid{Theory},\Conid{Formula})\;\Conid{Proof}{}\<[E]%
\\
\>[B]{}\hsindent{14}{}\<[14]%
\>[14]{}\mid \Conid{Elimination}\;(\Conid{Theory},\Conid{Formula})\;\Conid{Proof}\;\Conid{Proof}{}\<[E]%
\\
\>[B]{}\hsindent{14}{}\<[14]%
\>[14]{}\mathbf{deriving}\;(\Conid{Show},\Conid{Eq}){}\<[E]%
\\
\>[B]{}\Varid{label}\mathbin{::}\Conid{Proof}\to (\Conid{Theory},\Conid{Formula}){}\<[E]%
\\
\>[B]{}\Varid{label}\;(\Conid{Axiom}\;\Varid{a})\mathrel{=}\Varid{a}{}\<[E]%
\\
\>[B]{}\Varid{label}\;(\Conid{Introduction}\;\Varid{a}\;\anonymous )\mathrel{=}\Varid{a}{}\<[E]%
\\
\>[B]{}\Varid{label}\;(\Conid{Elimination}\;\Varid{a}\;\anonymous \;\anonymous )\mathrel{=}\Varid{a}{}\<[E]%
\\
\>[B]{}\Varid{valid}\mathbin{::}\Conid{Proof}\to \Conid{Bool}{}\<[E]%
\\
\>[B]{}\Varid{valid}\;(\Conid{Axiom}\;(\Varid{g},\Varid{p}))\mathrel{=}\Varid{\Conid{Set}.member}\;\Varid{p}\;\Varid{g}{}\<[E]%
\\
\>[B]{}\Varid{valid}\;(\Conid{Introduction}\;(\Varid{g},\Conid{Implies}\;\Varid{p}\;\Varid{q})\;\Varid{c})\mathrel{=}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}(\Varid{fst}\mathbin{\$}\Varid{label}\;\Varid{c})\equiv \Varid{\Conid{Set}.insert}\;\Varid{p}\;\Varid{g}\mathrel{\wedge}(\Varid{snd}\mathbin{\$}\Varid{label}\;\Varid{c})\equiv \Varid{q}{}\<[E]%
\\
\>[B]{}\Varid{valid}\;(\Conid{Introduction}\;\anonymous \;\anonymous )\mathrel{=}\Conid{False}{}\<[E]%
\\
\>[B]{}\Varid{valid}\;(\Conid{Elimination}\;(\Varid{g},\Varid{p})\;\Varid{major}\;\Varid{minor})\mathrel{=}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}(\Varid{fst}\mathbin{\$}\Varid{label}\;\Varid{major})\equiv \Varid{g}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\mathrel{\wedge}(\Varid{fst}\mathbin{\$}\Varid{label}\;\Varid{minor})\equiv \Varid{g}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\mathrel{\wedge}(\Varid{snd}\mathbin{\$}\Varid{label}\;\Varid{major})\equiv \Conid{Implies}\;(\Varid{snd}\mathbin{\$}\Varid{label}\;\Varid{minor})\;\Varid{p}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
We note that we usually use the following notation to write nodes of natural deduction trees: $$\frac{Children}{Label},$$
ie, proof trees are displayed according to the program below: 
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Varid{asTex}\mathbin{::}\Conid{Proof}\to \Conid{String}{}\<[E]%
\\
\>[B]{}\Varid{asTex}\;(\Conid{Axiom}\;\Varid{a})\mathrel{=}\Varid{showLabel}\;\Varid{a}{}\<[E]%
\\
\>[B]{}\Varid{asTex}\;(\Conid{Introduction}\;\Varid{a}\;\Varid{c})\mathrel{=}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\text{\ttfamily \char34 \char92 \char92 dfrac\char123 \char34}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\plus \Varid{asTex}\;\Varid{c}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\plus \text{\ttfamily \char34 \char125 \char123 \char34}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\plus \Varid{showLabel}\;\Varid{a}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\plus \text{\ttfamily \char34 \char125 \char34}{}\<[E]%
\\
\>[B]{}\Varid{asTex}\;(\Conid{Elimination}\;\Varid{a}\;\Varid{c1}\;\Varid{c2})\mathrel{=}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\text{\ttfamily \char34 \char92 \char92 dfrac\char123 \char34}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\plus \Varid{asTex}\;\Varid{c1}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\plus \text{\ttfamily \char34 \char92 \char92 ,\char34}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\plus \Varid{asTex}\;\Varid{c2}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\plus \text{\ttfamily \char34 \char125 \char123 \char34}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\plus \Varid{showLabel}\;\Varid{a}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\plus \text{\ttfamily \char34 \char125 \char34}{}\<[E]%
\\
\>[B]{}\Varid{showLabel}\;(\Varid{g},\Varid{p})\mathrel{=}\text{\ttfamily \char34 \char92 \char92 \char123 \char34}\plus (\Varid{concat}\mathbin{\$}\Varid{\Conid{List}.intersperse}\;\text{\ttfamily \char34 ,\char34}\mathbin{\$}\Varid{map}\;\Varid{formula}\mathbin{\$}\Varid{\Conid{Set}.toList}\;\Varid{g})\plus \text{\ttfamily \char34 \char92 \char92 \char125 \char92 \char92 vdash~\char34}\plus \Varid{formula}\;\Varid{p}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks

\subsection{Natural Deduction \& BHK}
We can interpret the rules of natural deduction in BHK as follows. First, we take $\{\varphi_1,\varphi_2,\dots,\varphi_n\}\vdash \psi$ as 
``Given (black-box) demonstrations for each $\varphi_i$, there is some construction built out of the $\varphi_i$ that is a demonstration of $\psi$.''
Then, we can interpret the $\to$I rule, $\frac{\Gamma,\phi\vdash\psi}{\Gamma\vdash\phi\to\psi}$ as follows: 
``We have that given demonstrations for the contents of $\Gamma$ and for $\phi$ we can build out of those demonstrations a demonstration of $\psi$. 
Then, using the demonstrations for the contents of $\Gamma$, we can write that demonstration of $\psi$ with the demonstrations for $\phi$ erased 
and then write a program that takes as input a new demonstration of $\phi$ and inserts it into the blanks where the old demonstrations for $\phi$ were.  
This program takes as input a demonstration of $\phi$ and produces a demonstration of $\psi$, so it is a proof of $\phi\to\psi$.''
Finally, the $\to$E rule can be interpreted as applying the program that is the proof of the major premise to the proof of the minor premise 
to get a proof of the conclusion. 

\subsection{Natural Deduction \& Hilbert-Style Proofs}
Recall the Hilbert-style proof system for classical logic where we had only one inference rule, modus ponens, and instead had three axiom schemes
(we assume that $\to$ associates to the right for brevity):
\begin{itemize}
\item[$P_1$:] $\phi\to(\psi\to\phi)$. 
\item[$P_2$:] $(\phi\to(\psi\to\chi)) \to (\phi\to\psi)\to(\phi\to\chi)$.
\item[$P_3$:] $((\phi\to\bot)\to\bot)\to\phi$. 
\end{itemize}
The $\to$E rule clearly corresponds to modus ponens. 

What does $\to$I correspond to? We note that $P_1$ and $P_2$ in the Hilbert proof system are sufficient to prove the deduction theorem: 
\begin{theorem}[Deduction Theorem]
In the Hilbert proof system with only axioms $P_1$ and $P_2$, if $\Gamma,\phi\vdash\psi$, then, $\Gamma\vdash\phi\to\psi$.
\end{theorem}
We will delay the proof until we have introduced a slight variation on proof trees in order to prove a slightly stronger version of the theorem.
 
Further, we can show that every member of the axiom schemes $P_1$ and $P_2$ are theorems of IPC($\to$) in natural deduction: 
\begin{theorem}
For any triplet of propositions $(\phi, \psi,\chi)$, denote their corresponding axioms in the axiom schemes $P_1$ and $P_2$
as $P_{1,\phi,\psi}$ and $P_{2,\phi,\psi,\chi}$ respectively.  
Then, for all $\phi,\psi,\chi\in\Phi$, we have that in IPC($\to$), $\vdash P_{1,(\phi,\psi)}$ and $\vdash P_{2,(\phi,\psi,\chi)}$. 
\begin{proof}
For any $\phi,\psi$, the following is a natural deduction proof of $P_{1,\phi,\psi}$:
$$\frac{\dfrac{\phi ,\psi \vdash \phi }{\phi \vdash (\psi \to \phi )}}{\vdash (\phi \to (\psi \to \phi ))}.$$
We delay the proof of $P_2$ until after we have the Curry-Howard Isomorphism. 
\end{proof}
\end{theorem} 

\subsection{Intuitionistic Algebraic Semantics}
We would like to dwell a bit on the semantics of intuitionistic logic before moving on to the simply typed lambda-calculus. 
In specific, we would like to show that the set of statements provable by natural deduction in the implicational fragment 
is equal to the set of statements that are \textit{semantically} necessarily true according to the algebraic semantics
of the full system of intuitionistic logic. 

Further, we want to use the semantics of logical deduction to illustrate some important differences between intuitionistic logic
and classical logic. 
We noted in the previous section that natural deduction for the implicational fragment of intuitionistic logic corresponds to 
the Hilbert proof system in classical logic without the axiom $((\phi\to\bot)\to\bot)\to\phi$. 
This axiom can be interpreted as formalizing the idea of a proof (of a positive statement) by contradiction: 
that is, if $\neg\phi$ proves a contradiction, then $\phi$ must be true. 
The fact that this axiom is not given in intuitionistic logic can be seen as a consequence of the \textit{constructive} nature
of intuitionistic logic: it's not clear how a construction of a contradiction out of $\phi\to\bot$ can directly be used to make a
construction of $\phi$ itself.  
We would like to be able to actually prove that intuitionistic logic can't actually prove that in general $((\phi\to\bot)\to\bot)\to\phi$. 
We can do this semantically by appeal to a topological interpretation of the algebraic semantics of intuitionistic logic. 

\subsubsection{The Lindenbaum-Tarski Algebra of IPC($\to$)}
Let's try to construct the algebraic semantics of the full intuitionistic propositional calculus from the semantics of its implicational fragment.

Consider a theory $\Gamma$, and the following lemma about natural deduction:
\begin{lemma}
Let $\Gamma$ be a theory in $IPC(\to)$. Then the following are true:
\begin{itemize}
\item[1.] $\Gamma\vdash \varphi\to\varphi$
\item[2.] If $\Gamma\vdash \varphi\to\psi$ and $\Gamma\vdash \psi\to\chi$, then $\Gamma\vdash\varphi\to\chi$.
\item[3.] If $\Gamma\vdash \varphi\leftrightarrow\varphi'$, $\Gamma\vdash\psi\leftrightarrow\psi'$, and $\Gamma\vdash\varphi\to\psi$, 
then, $\Gamma\vdash\varphi'\to\psi'$. 
\begin{proof}
\begin{itemize}
\item[1.] $$\dfrac{\Gamma,\varphi\vdash\varphi}{\Gamma\vdash\varphi\to\varphi}.$$
\item[2.] Let $\frac{\Pi[\cup\Delta]}{\Gamma\cup\Delta\vdash \varphi\to\psi}$ be a proof of $\Gamma\vdash\varphi\to\psi$
with every instance of $\Gamma$ replaced with $\Gamma\cup\Delta$, 
and $\frac{\Sigma[\Delta]}{\Gamma\cup\Delta\vdash \psi\to\chi}$ be a proof of $\Gamma\vdash \psi\to\chi$ 
with the same substitutions.  
Then, 
$$
\dfrac{
\dfrac{
  \dfrac{\Gamma,\varphi\vdash\varphi\text{ } \Gamma,\varphi\vdash \varphi\to\psi}{\Gamma,\varphi\vdash\psi}\text{ }
  \Gamma,\varphi\vdash\psi\to\chi
  }
  {
  \Gamma,\varphi\vdash\chi
  }
}
{
  \Gamma\vdash\varphi\to\chi
}
$$
\item[3.] Follows from two applications of (2.).
\end{itemize}
\end{proof}
\end{itemize}
\end{lemma} 
Items (1.) and (2.) from the above lemma means that if we define $\phi\leq_\Gamma \psi$ as $\Gamma\vdash \phi\to\psi$ 
for any two formulae $\phi,\psi\in\Phi$ 
(or equivalently, $\Gamma,\phi\vdash\psi$), 
$\leq_\Gamma$ forms a preorder on the set of formulas $\Phi$. 
Then, defining the equivalence relation $\phi\sim_\Gamma\psi\iff\Gamma\vdash\phi\leftrightarrow\psi$,
we get that $\Phi/\sim_\Gamma$ is a partially ordered set under $\leq_\Gamma$ 
where the largest element, which we can denote as $1$, is the set of $\phi$ such that $\Gamma\vdash\phi$---
we note (1.) implies that this class is non-empty.  
We call $\Phi/\sim_\Gamma$ the \textit{Lindenbaum-Tarski algebra} for $\Gamma$. 

Further, item (3.) means that the connective $\to$
induces a binary operator $\to_\Gamma$ on $\Gamma\vdash\phi$ such that $[\psi]_\sim\to_\Gamma[\phi]_\sim=[\psi\to\phi]_\sim$.
The operator $\to_\Gamma$ obeys the axiom that $\phi\to_\Gamma\psi = 1$ if and only if $\phi \leq_\Gamma \psi$. 

We can interpret elements of $\Phi/\sim_\Gamma$ as classes of formulae that are semantically-equivalent
in the sense that the set of formulae whose demonstrations can be constructed from those 
of each element in the class are the same. 

\subsubsection{Heyting Algebras}
In the previous section we defined a way to assign semantic values to formulae
in a theory $\Gamma$ such formulae with the same semantic value could be considered
logically equivalent under $\Gamma$.
We noted that the semantic values have the structure of a partially ordered set
with a greatest element and has a single binary operator that interprets the
implicational fragment's single logical connectives. 

We would like to define an algebraic structure that can be used to assign values
to statements in the full intuitive propositional calculus with its full complement
of logical connectives: $\wedge,\vee,$ and $\bot$. 
We will call this algebraic structure a \textit{Heyting Algebra} $\mathcal{H}=(H,\vee,\wedge,\to,0,1)$. 

We would like $\vee$ and $\wedge$ to still obey the distributive lattice axioms. 
We will interpret $\bot$ as absurdity, and stipulate that in intuitive logic $\bot$ follows
the principle of explosion: for any $\phi$ and any $\Gamma,$ $\Gamma\vdash\bot\to\phi$. 
Thus we will interpret $\bot$ as always having the value of the least element, $0$, of the Heyting algebra.
 




\subsubsection{Soundness and Completeness}
\subsubsection{Topological Intepretation of Heyting Algebras}
\section{Simply-Typed Lambda Calculus}
We remember that in the BHK-interpretation a proof $\varphi\to\psi$ should correspond 
to a program that takes a proof of $\varphi$ and returns a proof of $\psi$. 
If we are to identify proofs with programs, then a proof of $\varphi\to\psi$ would then
be identified with a program that takes a program and returns another program. 
It would then be desirable to have a formal model of computation where the basic domain of programs
are other programs. 
This model of computation will be called the \textit{simply-typed lambda calculus}. 

Here, we will present the Church-system of simply-typed lambda calculus. 
We will note that there is also a Curry-system of simply-typed lambda calculus,
that is mostly equivalent. 

\subsection{Simple Types and Pre-Terms}
In the simply-typed lambda calculus, we have two sorts of objects: types and terms. 
Both types and terms will be using \textit{syntactic} rules; 
meanwhile, terms will be assigned at most one type by the \textit{typability} relation;
we can think of the subset of terms that can be assigned types as the set of terms that are
\textit{semantically} well-defined.  
A type in the simply-typed lambda calculus will be a string following the same syntactic rules as propositions in IPC($\to$). 
Thus we can immediately identify the set of simple types with $\Phi$.\footnote{
The types in the simply-typed lambda calculus are called ``simple'' as they lack (a) parameters or (b) recursion. 
For example, the following \ensuremath{\Conid{List}} type definition in Haskell would not be a simple type: 
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Conid{List}\;\Varid{a}\mathrel{=}\Conid{Cons}\;\Varid{a}\;(\Conid{List}\;\Varid{a})\mid \Conid{Empty}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
} 
In the context of the simply-typed lambda calculus, members of $PV$ are called \textit{type variables}. 
If $\sigma$ and $\tau$ are types and $\alpha$ is a type variable, 
we write $\sigma[\alpha:=\tau]$ to denote the type resulting from substitution of $\tau$
for every occurence of $\alpha$ in $\sigma$. 

Syntactically, programs in the lambda-calculus are first written in terms of the rules for forming \textit{pre-terms}. 
We begin with a countably infinite alphabet of variables $V$. 
Then, the set $\Lambda_\Phi^-$ of pre-terms is the smallest set of strings containing $V$ and closed under the following rules:
\begin{itemize}
\item If $x\in V$, $\phi\in\Phi$, and $M\in \Lambda_\Phi^-$, then, $(\lambda x .\phi \; M)\in \Lambda_\Phi^-$.
This rule is called \textit{abstraction} and can be roughly interpreted as defining a function $f\colon \phi\to \mathord{?}$ 
that can be written as $f(x) = M$. 
\item If $M,N\in \Lambda_\Phi^-$, then, $(M\; N)\in\Lambda_\Phi^-$. 
This rule is called \textit{application}; if $M$ evaluates to some function $f$ this should represent $f(N)$.  
\end{itemize}

That is, $\Lambda_\Phi^-$ corresponds to the set of strings representing the following Haskell data structure:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{11}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\mathbf{type}\;\Conid{V}\mathrel{=}\Conid{String}{}\<[E]%
\\
\>[B]{}\mathbf{data}\;\Conid{Term}\mathrel{=}\Conid{Variable}\;\Conid{V}{}\<[E]%
\\
\>[B]{}\hsindent{11}{}\<[11]%
\>[11]{}\mid \Conid{Abstraction}\;\Conid{V}\;\Conid{Formula}\;\Conid{Term}{}\<[E]%
\\
\>[B]{}\hsindent{11}{}\<[11]%
\>[11]{}\mid \Conid{Application}\;\Conid{Term}\;\Conid{Term}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks

For a pre-term $M\in \Lambda_\Phi^-$ in the lambda calculus, we call the set of variables $x$ appearing in $M$ 
outside of an abstraction term $(\lambda x.\phi \; M)$ the set of \textit{free variables} $FV(M)$. 
More formally, the set of free variables is defined inductively such that 
\begin{itemize}
\item $FV(x) = \{x\}$,
\item $FV(\lambda x. \phi \; M) = FV(M)\setminus\{x\}$, 
\item $FV(M\; N)= FV(M)\cup FV(N)$. 
\end{itemize} 

\subsection{Typability}
We can see the free variables of terms in the lambda-calculus as referring to black-box programs
of some type provided by an outside context, and computation in the lambda-calculus as manipulations
of those programs. 

We would like to see be able to check that given the black-box programs supplied by our context, 
the manipulations on those programs we define in a lambda-term make semantic sense. 
In particular, when we our context supplies a program $f$ with type $\phi\to\psi$, 
we mean that $(f x)$ (which we recall is the lambda calculus expression representing $f(x)$) 
only has a well defined meaning when $x$ has type $\phi$, 
so we want to make sure the computation our term specifies only ever applies $f$
to terms of type $\phi$. 

Thus: we call a finite $\Gamma\subset V\times\Phi$ such that 
$\Gamma$ defines a function from its \textit{domain} $\{x\in V\mid \exists \phi((x,\phi)\in\Gamma)\}$ to $\Phi$ 
a \textit{context}. 
We denote the range of the function $\Gamma$ defines as $|\Gamma|$. 
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\mathbf{type}\;\Conid{Context'}\mathrel{=}\Conid{\Conid{Map}.Map}\;\Conid{V}\;\Conid{Formula}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Denote by $C$ the set of such contexts $\Gamma$.  
We denote the pairs $(x,\phi)\in \Gamma$ as $x:\phi$, 
which we interpret as $\Gamma$ assigning the type $\phi$ to the variable $x$. 
We note that we use the same shorthands for denoting contexts in intuitionistic logic: 
eg, $\Gamma,x:\phi$ denotes $\Gamma\cup\{x:\phi\}$. 

Then, we can define a three-way relation between types $\Gamma\in C$, pre-terms $M\in\Lambda_\Phi^-$, and types $\phi\in\Phi$ called \textit{typability}, which we denote as $\Gamma\vdash M:\phi$. 

We define typability inductively and case-wise as follows:
\begin{itemize}
\item If $M$ is a free variable $x\in V$, then, $\Gamma\vdash M:\phi$ if and only if $x:\phi\in\Gamma$. 
\item If $M$ is equal to an application term $(P Q)$, then, $\Gamma\vdash M\colon\phi$ 
if and only if there exists some $\psi$ such that $\Gamma\vdash P \colon \psi\to\phi$ and $\Gamma\vdash Q\colon\psi$. 
\item If $M$ is equal to an abstraction term $\lambda x:\psi\; N$, then, $\Gamma\vdash P\colon\phi$
if and only if there exists some $\tau$ such that $\phi= \psi\to\tau$ and 
$\Gamma,x:\psi \vdash N\colon\tau$. 
In this term we treat the abstraction term as supplying the context of $N$
with an additional variable $x$ of type $\psi$,
and $\lambda x:\psi\: N$ as having the type of a function with domain $\psi$
and the codomain being whatever type $N$ has when evaluated after being supplied
an $x$ of type $\psi$.
\end{itemize} 

We call pre-terms $M$ such that there exists some $\Gamma$ and some $\phi$ such that $\Gamma\vdash M:\phi$
\textit{typable}. We note that if a pre-term $M$ has a type under $\Gamma$, that type is unique. 

Finally, we note the substitution lemma:
\begin{lemma}[Substitution]
If $\Gamma\vdash M:\phi$, then, $\Gamma[\alpha:=\tau]\vdash M[\alpha=\tau]:\phi[\alpha:=\tau].$
\end{lemma}

\subsection{Substitution and $\alpha$-equivalence}

The basic model of lambda calculus is computation by executing symbolic substitution rules. 
We will want to define two definitions of equivalence in the lambda-calculus. 
First, $\cong_\alpha$ will denote the fact that two strings (pre-terms) represent the same program,
ie, the same substitution rules.
Then, $\cong_\beta$ will denote the fact that two programs represent the same \textit{value}, 
ie, they will eventually evaluate to the same thing.

For a pre-term $M$ we write $M[x:=N]$ to denote the substitution of $N$ for $x$ in $M$. 
In doing so, we replace every \textit{free} instance of $x$ in $M$ by $N$, 
while preserving the set of free variables of $N$. 
Thus substitution is defined inductively as follows: 
\begin{itemize}
\item $x[x:=N] = N$
\item $y[x:=N] = y$ for $y\neq x$. 
\item $(P\; Q)[x:=N] = (P[x:=N]\; Q[x:=N])$.
\item $(\lambda x.\phi\; P)[x:=N] = (\lambda x.\phi\; P)$: instances of $x$ in $P$ are not free, so we don't replace them. 
\item $(\lambda y.\phi\; P)[x:=N] = (\lambda y.\phi\; P[x:=N])$ when $y\neq x$ and $y\notin FV(N)$: 
in this case the instances of $x$ in $P$ are still free, so should be replaced. 
We note that we run into a bit of difficulty when $y$ is a free variable of $N$: 
we want substitution to preserve the semantic meaning of $N$, 
wherein $y$ is a free variable referring to something in the outside context. 

Substituting $N$ directly into $P$ would cause $y$ to become bound by $\lambda y$, 
changing the meaning of $N$ as the instances of $y$ in $N$ would now refer to 
the argument variable $y$ of the lambda term. 

The solution is to stipulate that the names of argument variables used in a function definition
shouldn't matter: ie, $f(x) = g(x)$ should define the same function as $f(y) = g(y)$. 
Thus, we will rename the $y$ variable in the original abstraction term to something
that doesn't conflict with $N$ before substituting $N$ in. This leads us to our last rule: 
\item $(\lambda y.\phi\; P)[x:=N] = (\lambda z. \phi\; P[y:=z][x:=N])$ for some choice of $z\notin FV(P)\cup FV(N)$ when $y\neq x$ and $y\in FV(n)$. 
\end{itemize}

We want to expand on a bit more on the names of argument variables not mattering. 
We will eventually want to define $(\lambda x.\phi\; N)\; M$ as representing 
the substitution rule where we substitute all occurences of $x$ in $N$ with $M$. 
Its clear that the variable $x$ here is strictly temporary, and thus 
$(\lambda y.\phi\;N[x:=y]) M$ would represent the same substitution operation
as both $x$ and $y$ will be replaced with $M$ anyway. 

Thus we define the $\cong_\alpha$ as the smallest equivalence relation on $\Lambda_\Phi^-$
such that $(\lambda x:\phi\; N) = (\lambda y:\phi\; N[x:=y])$ 
and that is preserved under application and abstraction. 

We can thus define the set of \textit{terms} $\Lambda_\Phi$ in the simply-typed lambda calculus
by $\Lambda_\Phi=\Lambda_\Phi^-/\cong_\alpha$. 
Thus, while $\Lambda_\Phi^-$ represents the set of distinct representations of programs,
$\Lambda_\Phi$ can be seen as representing the set of distinct programs themselves. 

It should be fairly easy to see that if $P\cong_\alpha Q$ then $P[x:=N]\cong_\alpha Q[x:=N]$,
and that if $P \cong_\alpha Q$, then, $\Gamma\vdash P:\phi$ if and only if $\Gamma\vdash Q:\phi$. 
It follows that substitution and typability are also defined for terms $\Lambda_\Phi$.  

We proceed to define what it means to evaluate a program in the lambda calculus. 

\subsection{$\beta$-reduction}
We mentioned in the previous section that the abstraction term represents 
a symbolic substitution rule that can be evaluated when applied to another term
by an application term. 
That is, $(\lambda x:\phi\; N)\; M$ evaluates to $N[x:=M]$. 
We represent evaluation by the relation $\to_\beta$, 
which is defined to be the smallest relation such that
$((\lambda x:\phi\; N)\; M)\to_\beta N[x:=M]$ and $\to_\beta$ 
is preserved under application and abstraction. 

That is, $P\to_\beta Q$ if we can find somewhere in $P$ some application term
applying an abstraction term to another term and replacing that application term
with its evaluated form yields $Q$. 
We note that if $P$ contains multiple such application terms, 
we can choose different application terms to evaluate in each step 
to yield multiple $Q_i$ such that $P\to_\beta Q_i$. 

We note that if $\Gamma\vdash P :\phi$ and $P \to_\beta Q$, then, $\Gamma\vdash Q:\phi$.
We note that the converse is not true, as $P$ may be untypable, 
and an untypable term may reduce to a typable one.  

We define the multi-step $\beta$-reduction relation $\twoheadrightarrow_\beta$
to be the transitive-reflexive closure of $\to_\beta$, that is, $P\twoheadrightarrow_\beta Q$ 
if there is a chain of zero or more evaluations that reduces $P$ to $Q$. 

We call the transitive-reflexive-symmetric closure of $\to_\beta$ $\beta$-equivalence, or $\cong_\beta$. 

Finally, we call a term $N$ that does not reduce to any other term $M$ $\beta$-normal. 
We can see $\beta$-normal forms as the results of a halted chain of computations
in the lambda-calculus. 

We will now state a few more results without proof about $\beta$-reduction 
and typability before moving on to prove the Curry-Howard Isomorphism. 
\subsubsection{Church-Rosser Theorem} 
We would like to know thar if $P\cong_\beta Q$ then there is some evaluation path
such that $P$ and $Q$ eventually evaluate to the same term. 

Further, we would like to know that the $\beta$-normal form that 
results from an evaluation path of some $P$ is unique, that is, 
there do not exist $Q\neq R$ such that both $Q$ and $R$ are $\beta$-normal
and both $P\twoheadrightarrow_\beta Q$ and $P\twoheadrightarrow_\beta R$. 

These properties are guaranteed by the Church-Rosser Theorem. 
\begin{theorem}[Church-Rosser]
Let $P\twoheadrightarrow_\beta Q$ and $P\twoheadrightarrow_\beta R$. 
Then, there exists some $S$ such that $Q\twoheadrightarrow_\beta S$ 
and $R\twoheadrightarrow_\beta S$. 
\end{theorem}
Two corollaries immediately follow. 
\begin{corollary}
For all $P \in \Lambda_\Phi$, there exists at most one $\beta$-normal
$Q\in \Lambda_\Phi$ such that $P \cong_\beta Q$. 
\end{corollary}
\begin{corollary}
If both $P\in\Lambda_\Phi$ and $Q\in\Lambda_\Phi$ are typable under $\Gamma$, 
and $P\cong_\beta Q$, then $P$ and $Q$ have the same type under $\Gamma$. 
\end{corollary}
\subsection{Weak-Normalization}
We now present one way in which a term being typable is a guarantee
of it being semantically well defined. 
\begin{theorem}[Weak Normalization]
If $P$ is typable, then there exists some $\beta$-normal $N$ such that
$P\twoheadrightarrow_\beta N$. 
\end{theorem}
This theorem implies that typability implies that the computation expressed 
by the lambda term halts.

It follows that the \textit{typable} subset of the simply-typed lambda calculus
is not Turing complete. 

\begin{remark}
We will note that the weak-normalization property is not true of terms in general. 
In particular, if we ignore the typability restriction we can define the fixed-point
or $Y$ combinator that has the property that $f\; (Y \; f) \cong_\beta Y\; f$. 
This allows the us to implement full recursion, including terms that never terminate. 

We note that while there is no typable version of $Y$, sometimes $Y\; f$ can $\beta$-reduce
to a typable term. 
\end{remark}

\section{The Curry-Howard Correspondence}
Now that we've provided the basic properties of both natural deduction and the simply-typed lambda-calculus, 
we can present the correspondence. 

\begin{theorem}
Let $\phi\in\Phi$. 
Then, a context $\Gamma\vdash \phi$ in natural deduction 
if and only if $\Gamma = |\Gamma'|$ where $\Gamma'$ is a context in the simply-typed lambda calculus
and there exists some lambda term $M\in\Lambda_\Phi$ such that $\Gamma'\vdash M:\phi$. 
\begin{proof}
First we prove that $\Gamma'\vdash M:\phi$ implies that $|\Gamma'| \vdash \phi$. 
We claim there is a surjection $\chi$ from $\{(\Gamma,M)\in C\times\Lambda_\Phi\mid \text{M is typable under }\Gamma\}$ 
to proofs in natural deduction such that if $\Gamma'\vdash M:\phi$, then $\chi(\Gamma',M)$ is a proof of $|\Gamma'|\vdash \phi$. 
We define $\chi(\Gamma',M)$ inductively as follows: 
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Varid{range}\mathbin{::}\Conid{Context'}\to \Conid{Context}{}\<[E]%
\\
\>[B]{}\Varid{range}\mathrel{=}\Varid{\Conid{Set}.fromList}\mathbin{\circ}\Varid{\Conid{Map}.elems}{}\<[E]%
\\[\blanklineskip]%
\>[B]{}\Varid{termToProof}\mathbin{::}\Conid{Context'}\to \Conid{Term}\to \Conid{Maybe}\;\Conid{Proof}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
First, when $M=x$, we have that if $\Gamma'\vdash x:\phi$ for some $\phi$, then 
$x:\phi\in\Gamma'$, so $\phi\in |\Gamma'|$. Then, we can define $\chi(\Gamma',M) = (|\Gamma'|\vdash \phi)$,
and $\chi(\Gamma',M)$ is a proper proof of $|\Gamma'|\vdash\phi$ under the axiom rule. 
This corresponds to the following code in Haskell: 
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Varid{termToProof}\;\Varid{c}\;(\Conid{Variable}\;\Varid{v})\mathrel{=}\Varid{fmap}\;(\Conid{Axiom}\mathbin{\circ}(\Varid{range}\;\Varid{c},))\mathbin{\$}\Varid{\Conid{Map}.lookup}\;\Varid{c}\;\Varid{v}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
Secondly, when $M = (P\; Q)$, we get that $\Gamma'\vdash M:\phi$ only if 
there exists some $\psi$ such that $\Gamma'\vdash P:\psi\to\phi$ and 
$\Gamma'\vdash P:\psi$. 

Then, $$\chi(\Gamma', M) = \frac{\chi(\Gamma',P)\text{ }\chi(\Gamma',Q)}{|\Gamma'|\vdash \phi}$$
is a proof of $|\Gamma'|\vdash\phi$ using the $\to$E rule as $\chi(\Gamma',P)$ is a proof of $\psi\to\phi$ 
and $\chi(\Gamma',Q)$ is a proof of $\psi$. 
Or, in Haskell,
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{7}{@{}>{\hspre}l<{\hspost}@{}}%
\column{9}{@{}>{\hspre}l<{\hspost}@{}}%
\column{11}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Varid{termToProof}\;\Varid{c}\;(\Conid{Application}\;\Varid{p}\;\Varid{q})\mathrel{=}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\mathbf{case}\;(\Varid{termToProof}\;\Varid{c}\;\Varid{p},\Varid{termToProof}\;\Varid{c}\;\Varid{q})\;\mathbf{of}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}(\Conid{Just}\;\Varid{proofP},\Conid{Just}\;\Varid{proofQ})\to {}\<[E]%
\\
\>[5]{}\hsindent{2}{}\<[7]%
\>[7]{}\mathbf{case}\;(\Varid{label}\;\Varid{proofP},\Varid{label}\;\Varid{proofQ})\;\mathbf{of}{}\<[E]%
\\
\>[7]{}\hsindent{2}{}\<[9]%
\>[9]{}((\anonymous ,\Conid{Implies}\;\Varid{psi}\;\Varid{phi}),(\anonymous ,\Varid{psi'}))\mid \Varid{psi}\equiv \Varid{psi'}\to {}\<[E]%
\\
\>[9]{}\hsindent{2}{}\<[11]%
\>[11]{}\Conid{Just}\;\Conid{Elimination}\;(\Varid{range}\;\Varid{c},\Varid{phi})\;\Varid{proofP}\;\Varid{proofQ}{}\<[E]%
\\
\>[7]{}\hsindent{2}{}\<[9]%
\>[9]{}\anonymous \to \Conid{Nothing}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}\anonymous \to \Conid{Nothing}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks

Finally, when $M = (\lambda x:\phi\; N)$, we get that if $M$ is typable under $\Gamma'$
then for some $\tau$, $\Gamma'\vdash M:\phi\to\tau$ and $\Gamma',x:\phi\vdash N:\tau$. 

Then, $$\chi(\Gamma',M) = \frac{\chi(\Gamma'\cup\{x:\phi\},N)}{|\Gamma'|\vdash \phi\to\tau}$$
is a valid natural deduction proof of $|\Gamma'|\vdash\phi\to\tau$ under the $\to$I rule 
as $\chi(\Gamma'\cup\{x:\phi\})$ is a valid proof of $|\Gamma'|,\phi\vdash\tau$. 
Or, in Haskell,
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{5}{@{}>{\hspre}l<{\hspost}@{}}%
\column{7}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Varid{termToProof}\;\Varid{c}\;(\Conid{Abstraction}\;\Varid{x}\;\Varid{phi}\;\Varid{n})\mathrel{=}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\Varid{fmap}\;{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}(\lambda \Varid{proofN}\to {}\<[E]%
\\
\>[5]{}\hsindent{2}{}\<[7]%
\>[7]{}\Conid{Introduction}\;(\Varid{range}\;\Varid{c},\Conid{Implies}\;\Varid{phi}\;(\Varid{snd}\mathbin{\$}\Varid{label}\;\Varid{proofN}))\;\Varid{proofN}{}\<[E]%
\\
\>[3]{}\hsindent{2}{}\<[5]%
\>[5]{}){}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\mathbin{\$}\Varid{termToProof}\;(\Varid{\Conid{Map}.insert}\;\Varid{x}\;\Varid{phi}\;\Varid{c})\;\Varid{n}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks

Then, if we show that $\chi$ is a surjection, we prove the equivalence. 

We note however that for any proof of $\Gamma\vdash\phi$ we can construct a $\Gamma',M$ such that $\chi(\Gamma',M)$ is 
a proof of $\Gamma\vdash\phi$ as follows. First, construct $\Gamma'$ from $\Gamma = \{\psi_1,\psi_2,\dots,\psi_n\}$ 
by choosing $\{x_1,x_2, \dots,x_n\}\in V$ and letting $\Gamma' = \{x_1:\psi_1,x_2:\psi_2,\dots,x_n:\psi_n\}$. 

Then, for $\Gamma'$ such that $|\Gamma'| = \Gamma$ and a proof of $\Gamma\vdash\phi$ we construct the corresponding
lambda term inductively as follows:

If the proof is an axiom $\Gamma,\phi\colon \phi$, then we have that there exists some $i$ such that $\psi_i\in \Gamma$
so $\Gamma'\vdash x:\phi$. 

If the proof is a $\to$E rule, with $P$ and $Q$ being the proofs of $\psi\to\phi$ and $\psi$ respectively, 
we simply apply the lambda term corresponding to $\Gamma'$ and $P$ to the one corresponding to $\Gamma'$ and $Q$. 

If the proof is a $\to$I rule, with $\phi = \sigma\to\tau$ and $N$ being a proof that $\Gamma,\sigma\vdash\tau$,
then, choose some $x\in V$ such that $x$ is not in the dommain of $\Gamma'$. 
Then the proof corresponds to the abstraction term $(\lambda x:\sigma\; N')$ where $N'$ is the term
corresponding to $N$ under the augmented context $\Gamma' \cup \{x:\sigma\}$. 

The resulting term corresponds to the original proof under the map $\chi$, thus $\chi$ is surjective. 
\end{proof}
\end{theorem}

\subsection{Application: Consistency}
We can use the correspondence to prove the consistency of IPC($\to$) in the case of an empty context.
Here, consistency is defined to mean that there exists some formula $\phi$ such that $\not\vdash\phi$. 
\begin{theorem}
IPC($\to$) is consistent. 
\begin{proof}
Suppose not. Then, let $\phi$ be a propositional variable: we must have that $\vdash\phi$. 

But that means that there must be some term $M$ such that $\vdash M\colon\phi$. 
Since $M$ is typable, it must be reducible to a $\beta$-normal form $M'$ that has the same type. 
Consider the root of the syntax tree of $M'$:
$M'$ cannot be a variable $x$, since then $x\colon\phi\in\{\}$ by the typability rule. 

If $M'$ is an application term, then we note that its left child cannot be an abstraction term, 
since otherwise $M'$ wouldn't be $\beta$-normal. 
We further note that since subterms of $\beta$-normal terms are themselves $\beta$-normal,
if $M'$ is an application term such that the depth of the left-most leaf is $h$, 
either $h=1$ in which case $M' = (x\; Q)$ for $x\in V$,
or $M' = (P\; Q)$ for an application term with left-height $h-1$. 
But, if $M'=(x\; Q)$ then $\vdash M':\phi$ only if $\vdash x :\psi\to\phi$ for some $\psi$, 
but we know that is not true already.
However, if for all application terms with left-height $h$ we have that $\not\vdash P:\phi$
for any $\phi$, then we get that $\not\vdash (P \; Q) :\phi$ for any $\phi$. 
So $M'$ is not an application term. 

Then, $M'$ is an abstraction term. But abstraction terms are only typable by types of the form $\sigma\to\tau$,
so if $\phi$ is a propositional variable $\not\vdash M' \colon\phi$, so $\not\vdash \phi$. 

So, IPC($\to$) is consistent.
\end{proof}
\end{theorem}
\subsection{Application: Untypability of the Y combinator}
While the untypability of the $Y$ combinator follows from the weak-normalization property
and thus the Turing-incompleteness of the typable subset of the lambda-calculus,
it is also provable using the Curry-Howard isomorphism. 

In particular, we show $Y$ is a proof of inconsistency. 
\begin{theorem}
Let $\sigma$ be a propositional variable. 
Let $Y$ be a term with no free variables such that for any $f\colon \sigma\to\sigma$,
$f(Y\; f) \cong_\beta Y\; f$. 
Then, $Y$ is not typable.
\begin{proof}
Since $Y$ has no free variables it is typable only if there is some $\phi$
such that $\vdash Y:\phi$. 
If $Y$ is typable, then, $(Y\; f)$ is, and $(f\;(Y\; f))$ is, and, since
they are $\beta$-equivalent, those two types are the same. 
But we note that $(Y\; f)$ is typable only if $\phi$ has the form 
$(\sigma\to\sigma)\to\tau$ for some $\tau$ and $(f\; (Y\; f))$ is 
typable only if that $\tau$ is equal to $\sigma$. 

So, if $Y$ were typable then $\vdash Y: (\sigma\to\sigma)\to\sigma$.

By the substitution lemma, we have that for any type $\phi$ we have that
$\vdash Y[\sigma:=\phi] : (\phi\to\phi)\to\phi$. 
But that means that for any $\phi$ we have that in natural deduction
$\vdash (\phi\to\phi)\to\phi$. 
Then, we since for any $\phi$ we have that $\vdash\phi\to\phi$,
we have that $\vdash\phi$ for any $\phi$.

But that means that natural deduction is inconsistent, which we know is not true.
So $Y$ is untypable. 
\end{proof} 
\end{theorem}
\end{document}

